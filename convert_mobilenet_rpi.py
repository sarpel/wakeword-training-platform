import torch
import torch.onnx
import numpy as np
import os
import sys

# 1. Proje dizinini yola ekle
sys.path.append(os.getcwd())

# --- DÃœZELTME BURADA ---
# mobilenetv3.py yok, sÄ±nÄ±f architectures.py iÃ§inde tanÄ±mlÄ±.
try:
    from src.models.architectures import MobileNetV3
    print("âœ… MobileNetV3 sÄ±nÄ±fÄ± 'architectures.py' iÃ§inden yÃ¼klendi.")
except ImportError as e:
    print(f"âŒ HATA: Model sÄ±nÄ±fÄ± yÃ¼klenemedi. Detay: {e}")
    print("LÃ¼tfen 'src/models/architectures.py' dosyasÄ±nÄ±n iÃ§inde 'MobileNetV3' sÄ±nÄ±fÄ± olduÄŸundan emin ol.")
    sys.exit(1)

# --- AYARLAR ---
CHECKPOINT_PATH = "models/checkpoints/best_model.pt"
ONNX_PATH = "hey_katya_rpi.onnx"
TFLITE_OUTPUT_FOLDER = "tflite_rpi_output"

# Model Parametreleri (Senin RPi Heavy Config'inle AYNI)
MODEL_PARAMS = {
    "num_classes": 2,
    "hidden_size": 128,       # Config: 128
    "num_layers": 3,          # Config: 3
    "bidirectional": True,    # Config: True
    "dropout": 0.2,
    "tcn_num_channels": [64, 128, 256],
    "tcn_kernel_size": 5,
    "tcn_dropout": 0.2,
    "cddnn_hidden_layers": [128, 64],
    "cddnn_context_frames": 11,
    "cddnn_dropout": 0.2
}

# Ses AyarlarÄ± (HD Model - 64 Mels)
N_MELS = 64
N_FRAMES = 101 

def run_conversion():
    print("ğŸš€ Raspberry Pi Modeli DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor...")
    
    # 1. Modeli BaÅŸlat
    try:
        model = MobileNetV3(**MODEL_PARAMS)
    except TypeError as e:
        print(f"âŒ HATA: Model parametrelerinde uyuÅŸmazlÄ±k var: {e}")
        return

    # 2. Checkpoint YÃ¼kle
    print(f"ğŸ“‚ Checkpoint yÃ¼kleniyor: {CHECKPOINT_PATH}")
    if not os.path.exists(CHECKPOINT_PATH):
        print(f"âŒ DOSYA BULUNAMADI: {CHECKPOINT_PATH}")
        return

    try:
        checkpoint = torch.load(CHECKPOINT_PATH, map_location='cpu')
        
        # State dict temizliÄŸi (model. Ã¶n eklerini kaldÄ±r)
        if 'state_dict' in checkpoint:
            state_dict = {k.replace('model.', ''): v for k, v in checkpoint['state_dict'].items()}
        else:
            state_dict = checkpoint
            
        model.load_state_dict(state_dict)
        print("âœ… AÄŸÄ±rlÄ±klar baÅŸarÄ±yla yÃ¼klendi.")
    except Exception as e:
        print(f"âŒ HATA: Checkpoint yÃ¼klenirken sorun Ã§Ä±ktÄ±: {e}")
        return

    model.eval()

    # 3. ONNX Export
    dummy_input = torch.randn(1, N_MELS, N_FRAMES)
    
    print("ğŸ”„ ONNX'e Ã§evriliyor...")
    try:
        torch.onnx.export(
            model,
            dummy_input,
            ONNX_PATH,
            input_names=['input'],
            output_names=['output'],
            opset_version=13,
            dynamic_axes=None 
        )
        print(f"âœ… ONNX dosyasÄ± oluÅŸturuldu: {ONNX_PATH}")
    except Exception as e:
        print(f"âŒ ONNX Export hatasÄ±: {e}")
        return

    # 4. Kalibrasyon Verisi
    calib_data = np.random.randn(1, N_MELS, N_FRAMES).astype(np.float32)
    np.save("calib_data_rpi.npy", calib_data)

    # 5. TFLite DÃ¶nÃ¼ÅŸÃ¼mÃ¼
    print("â³ TFLite'a Ã§evriliyor (onnx2tf)...")
    
    # KlasÃ¶r oluÅŸtur
    if not os.path.exists(TFLITE_OUTPUT_FOLDER):
        os.makedirs(TFLITE_OUTPUT_FOLDER)
        
    # Windows'ta 'onnx2tf' komutu bazen doÄŸrudan Ã§alÄ±ÅŸmaz, python -m ile Ã§aÄŸÄ±rÄ±yoruz
    # AyrÄ±ca Windows'ta onnxsim hatasÄ± alabilirsin, -nos (no simplification) eklenebilir ama Ã¶nce normal deneyelim.
    cmd = f"onnx2tf -i {ONNX_PATH} -o {TFLITE_OUTPUT_FOLDER} -oiqt -cind input calib_data_rpi.npy 0 1"
    
    ret = os.system(cmd)
    
    if ret == 0:
        print("\n" + "="*40)
        print(f"ğŸ‰ RPi MODELÄ° HAZIR!")
        print(f"ğŸ“‚ Dosya: {TFLITE_OUTPUT_FOLDER}/hey_katya_rpi_dynamic_range_quant.tflite")
        print("="*40)
    else:
        print("\nâŒ onnx2tf komutu baÅŸarÄ±sÄ±z oldu.")
        print("EÄŸer 'onnx2tf' bulunamadÄ± hatasÄ± alÄ±yorsan: 'pip install onnx2tf tensorflow' yaptÄ±ÄŸÄ±ndan emin ol.")
        print("Windows'ta sorun yaÅŸarsan bu iÅŸlemi WSL (Linux) ortamÄ±nda yapman gerekebilir.")

if __name__ == "__main__":
    run_conversion()