# Performance & Environment Optimization
# Quantization Backend: fbgemm (Windows/x86), qnnpack (Linux/ARM/WSL)
# Windows default: fbgemm
# Linux/ARM default: qnnpack
QUANTIZATION_BACKEND=qnnpack

# Multiprocessing Start Method: spawn (Windows/Safe), fork (Linux/Fast)
# Windows default: spawn
# Linux default: fork
MP_START_METHOD=fork

# Use Torch Compile (Triton): true (Linux/GPU), false (Windows)
# Only supported on Linux with NVIDIA GPU
USE_TRITON=true

# Global Configuration Overrides
TRAINING_NUM_WORKERS=8
TRAINING_BATCH_SIZE=64

# Weights & Biases
WANDB_PROJECT=wakeword-detection
WANDB_ENTITY=
